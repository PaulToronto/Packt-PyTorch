{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1269ff19",
   "metadata": {},
   "source": [
    "# 1-4 - Foundations and Core Concepts of PyTorch - Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eec575",
   "metadata": {},
   "source": [
    "## Underfitting Overfitting (101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81435df2",
   "metadata": {},
   "source": [
    "### Regression Example\n",
    "\n",
    "#### Underfitting\n",
    "\n",
    "<img src='../images/underfitting.png'/>\n",
    "\n",
    "- Above we see an example of **underfitting** \n",
    "- Underfitting is closely related to **high bias**\n",
    "- The model is too simple for the given complexity\n",
    "- The vertical difference between the actual datea and the predicted values are pretty high\n",
    "\n",
    "#### Overfitting\n",
    "\n",
    "<img src='../images/overfitting.png'/>\n",
    "\n",
    "- Here we see an example of **overfitting**\n",
    "- Overfitting is closely related to **high variance**\n",
    "- The model learned the noise, so it will not generalize well to new data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37c293f",
   "metadata": {},
   "source": [
    "### Classification Example\n",
    "\n",
    "<img src='../images/classification.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b38b1f",
   "metadata": {},
   "source": [
    "### Good Fits\n",
    "\n",
    "<img src='../images/good_fits.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3cc4f3",
   "metadata": {},
   "source": [
    "### Bias and Variance\n",
    "\n",
    "<img src='../images/bias_variance.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49354d66",
   "metadata": {},
   "source": [
    "### Bias\n",
    "\n",
    "- Bias is the difference in prediction and actual values of **training** data\n",
    "- Bias is a measure of how well a model is fitted to the training data\n",
    "    - High bias means the model is not very well fitted\n",
    "- Example of High Bias / Low Variance\n",
    "  - $R^2$ ranges from 0 t0 1. 1 is a pefect fit\n",
    "  - $R^2$ = 0.5 for training\n",
    "  - $R^2$ = 0.48 for validation\n",
    "  - The $R^2$ for the training data is relatively low and the score for the validation data is not that much worse $\\rightarrow$ High Bias / Low Variance\n",
    "\n",
    "  <img src='../images/high_bias.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d81dc4",
   "metadata": {},
   "source": [
    "### Variance\n",
    "\n",
    "- Variance is the difference in the prediction of **training** data vs. prediction of **validation** data\n",
    "- Example of Low Bias / High Variance\n",
    "  - $R^2 = 0.97$ for training \n",
    "  - $R^2 = 0.3$ for validation\n",
    "\n",
    " <img src='../images/high_variance.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83ec252",
   "metadata": {},
   "source": [
    "### Complexity, Underfitting and Overfitting\n",
    "\n",
    "- Adding more parameters to a model increases model complexity\n",
    " - Bias goes down\n",
    " - Variance goes up "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b44d5d",
   "metadata": {},
   "source": [
    "### Bias Variance Tradeoff\n",
    "\n",
    "- Goal: \n",
    "  - low bias / low variance\n",
    "  - good prediction performance\n",
    "- Bias and Variance have opposite direction\n",
    "- Linear ML algorithms typically high bias, low variance\n",
    "- Non-linear ML algorithms typically low bias, high variance\n",
    "- Non-linear ML algorithms often have hyperparameters for tuning\n",
    "\n",
    " <img src='../images/bias_variance_tradeoff.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03396831",
   "metadata": {},
   "source": [
    "## Train Test Split (101)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
